{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_time_seq_pth(path):\n",
    "    \"\"\"\n",
    "    This function retrieves the results of a certain pthread computation.\n",
    "\n",
    "    Input:\n",
    "     - path: inner path to the folder containing a result (consider to address a path/job.out)\n",
    "\n",
    "    Output:\n",
    "     - A numpy array of 3 unsigned integers (matched patterns and the 2 checksums),\n",
    "       or\n",
    "     - [-1, -1, -1] meaning an absence of attemps\n",
    "       or\n",
    "     - [-2, -2, -2] meaning a non-finished run due to interruption\n",
    "       or\n",
    "     - [-3, -3, -3] meaning an aborted run\n",
    "    \"\"\"\n",
    "    # Checking that the computation was at least attempted\n",
    "    if \"job.out\" and \"job.err\" in os.listdir(path):\n",
    "        f = open(path + \"/job.err\", \"r\")\n",
    "        # Checking that the computation had no errors\n",
    "        if (len(f.readlines()) > 0):\n",
    "            return np.array([-3, -3, -3])\n",
    "\n",
    "        f = open(path + \"/job.out\", \"r\")\n",
    "\n",
    "        # Checking that the computation has gone through correctly\n",
    "        lines = f.readlines()\n",
    "        if len(lines) > 0:\n",
    "            result = lines[2].split()[1:]\n",
    "            result[0] = result[0][:-1]\n",
    "            result[1] = result[1][:-1]\n",
    "            return np.array(result, dtype=np.uint64)\n",
    "        else:\n",
    "            return np.array([-2, -2, -2])\n",
    "        \n",
    "    return np.array([-1, -1, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_time_mpi(path):\n",
    "    \"\"\"\n",
    "    This function retrieves the results of a certain mpi computation.\n",
    "\n",
    "    Input:\n",
    "     - path: inner path to the folder containing a result (consider to address a path/job.out)\n",
    "\n",
    "    Output:\n",
    "     - A numpy array of 3 unsigned integers (matched patterns and the 2 checksums),\n",
    "       or\n",
    "     - [-1, -1, -1] meaning an absence of attemps\n",
    "       or\n",
    "     - [-2, -2, -2] meaning a non-finished run due to interruption\n",
    "       or\n",
    "     - [-3, -3, -3] meaning an aborted run\n",
    "    \"\"\"\n",
    "    # Checking that the computation was at least attempted\n",
    "    if \"job.out.0\" and \"job.err.0\" in os.listdir(path):\n",
    "        f = open(path + \"/job.out.0\", \"r\")\n",
    "        # Checking that the computation had no errors\n",
    "        try:\n",
    "          lines = f.readlines()\n",
    "          result = lines[2].split()[1:]\n",
    "          result[0] = result[0][:-1]\n",
    "          result[1] = result[1][:-1]\n",
    "          return np.array(result, dtype=np.uint64)\n",
    "        except:\n",
    "          return np.array([-3, -3, -3])\n",
    "    \n",
    "    # Interrupted runs only produce the log file\n",
    "    elif \"job.log\" in os.listdir(path):\n",
    "       return np.array([-2, -2, -2])\n",
    "    \n",
    "    return np.array([-1, -1, -1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -2, -2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "retrieve_time_mpi(\"results/logs/mpi/nodes_2/seq_length_20/patterns_20/mean_path_length_4/2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_settings(path):\n",
    "    \"\"\"\n",
    "    This function retrieves all the settings for a certain measurement.\n",
    "\n",
    "    Input:\n",
    "     - path: inner path to the folder containing a result (consider to address a path/job.out)\n",
    "\n",
    "    Output: \n",
    "     - A numpy array of settings in format np.int64\n",
    "    \"\"\"\n",
    "    options = path.split(\"/\")\n",
    "    settings = np.array([], dtype=np.int64)\n",
    "    for set in options:\n",
    "        if not str.isalpha(set.split(\"_\")[-1]):\n",
    "            settings = np.append(settings, np.int64(set.split(\"_\")[-1]))\n",
    "            \n",
    "    return settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, True]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "retrieve_settings(\"results/logs/sequential/seq_length_25/patterns_15/mean_path_length_4\")\n",
    "[os.path.isdir(\"results/logs/sequential\" + \"/\" + x) for x in os.listdir(\"results/logs/sequential\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These indexes allow us to rapidly swap the number of parameter in consideration during generation.\n",
    "\n",
    "sequential_idx = {\"seq_length\": 0, \"patterns\": 1, \"mean_path_length\": 2, \"test_n\": 3}\n",
    "pthreads_idx = {\"threads\": 0, \"seq_length\": 1, \"patterns\": 2, \"mean_path_length\": 3, \"test_n\": 4}\n",
    "mpi_idx = {\"nodes\": 0, \"seq_length\": 1, \"patterns\": 2, \"mean_path_length\": 3, \"test_n\": 4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path, dataset, retrieval_f):\n",
    "    \"\"\"\n",
    "    This function recursively explores the results folder and gathers data about the measurements.\n",
    "\n",
    "    Input:\n",
    "     - path: the path of the dataset\n",
    "     - dataset: whatever numpy array of np.uint with the same dimension as the measurement variables\n",
    "\n",
    "     Output: \n",
    "      - The dataset as a numpy array of np.uint. The shape of the array is (measurements, variables),\n",
    "        where the last 3 variables are the results of the computation\n",
    "    \"\"\"\n",
    "    new_dataset = np.copy(dataset)\n",
    "    if not os.path.isdir(path):\n",
    "        return dataset\n",
    "    elif not np.any([os.path.isdir(path + \"/\" + x) for x in os.listdir(path)]):\n",
    "        results = retrieval_f(path)\n",
    "        settings = retrieve_settings(path)\n",
    "        row = np.append(settings, results.astype(np.int64)).reshape(1, -1)\n",
    "        return np.append(new_dataset, row, axis=0)\n",
    "    else:\n",
    "        for dir in os.listdir(path):\n",
    "            new_dataset = create_dataset(path + \"/\" + dir, new_dataset, retrieval_f)\n",
    "\n",
    "    return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      4,      15,      15, ...,   32776,   42103,   45435],\n",
       "       [      4,      15,      15, ...,   32776,   42103,   45435],\n",
       "       [      4,      15,      15, ...,   32776,   42103,   45435],\n",
       "       ...,\n",
       "       [      8,      10,      20, ..., 1048576,   20039,    6014],\n",
       "       [      8,      10,      20, ..., 1048576,   20039,    6014],\n",
       "       [      8,      10,      20, ..., 1048576,   20039,    6014]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "sequential = create_dataset(\"results/logs/sequential\", np.zeros(shape=(1, len(sequential_idx) + 3), dtype=np.int64), retrieval_f=retrieve_time_seq_pth)[1:,]\n",
    "create_dataset(\"results/logs/mpi\", np.zeros(shape=(1, len(mpi_idx) + 3), dtype=np.int64), retrieval_f=retrieve_time_mpi)[1:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pthreads = create_dataset(\"results/logs/pthreads\", np.zeros(shape=(1, len(pthreads_idx) + 3), dtype=np.int64), retrieval_f=retrieve_time_seq_pth)[1:,]\n",
    "sequential = create_dataset(\"results/logs/sequential\", np.zeros(shape=(1, len(sequential_idx) + 3), dtype=np.int64), retrieval_f=retrieve_time_seq_pth)[1:, :]\n",
    "mpi = create_dataset(\"results/logs/mpi\", np.zeros(shape=(1, len(mpi_idx) + 3), dtype=np.int64), retrieval_f=retrieve_time_mpi)[1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   10,    10,     4, ...,  1147,   368, 39054],\n",
       "       [   10,    10,     4, ...,  1147,   368, 39054],\n",
       "       [   10,    10,     4, ...,  1147,   368, 39054],\n",
       "       ...,\n",
       "       [   20,    25,    20, ...,    -2,    -2,    -2],\n",
       "       [   20,    25,    20, ...,    -2,    -2,    -2],\n",
       "       [   20,    25,    20, ...,    -2,    -2,    -2]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential[np.lexsort(np.transpose(sequential)[::-1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking correctness of computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctness(path, method_idx, retrieval_f):\n",
    "    \"\"\"\n",
    "    This function checks the correctness of a computation and tests it against sequential's results.\n",
    "\n",
    "    Input:\n",
    "     - path: path to the results\n",
    "    \n",
    "    Output:\n",
    "     - self-described\n",
    "    \"\"\"\n",
    "    # Creating the results datasets\n",
    "    sequential = create_dataset(\"results/logs/sequential\", np.zeros(shape=(1, len(sequential_idx) + 3), dtype=np.int64), retrieve_time_seq_pth)[1:,]\n",
    "    sequential = sequential[np.lexsort(np.transpose(sequential)[::-1])]\n",
    "    dataset = create_dataset(path, np.zeros(shape=(1, len(method_idx) + 3), dtype=np.int64), retrieval_f)[1:,]\n",
    "    dataset = dataset[np.lexsort(np.transpose(dataset)[::-1])]\n",
    "    total_tests_sequential = sequential.shape[0]\n",
    "    total_tests_dataset = dataset.shape[0]\n",
    "\n",
    "    # First check: runs with errors\n",
    "    errors = dataset[np.where(dataset[:, -3] == -3)]\n",
    "    if errors.shape[0] == 0:\n",
    "        print(\"1. No errors\")\n",
    "    else:\n",
    "        print(f\"1. There where {errors.shape[0]} errors:\")\n",
    "        print(errors[:, :-3])\n",
    "\n",
    "    # Second checks: runs non - terminated (where sequential terminated)\n",
    "    errors = np.unique(dataset[np.where(dataset[:, -3] == -2)][:, 1:-3], axis=0)\n",
    "    seq_errors = np.unique(sequential[np.where(sequential[:, -3] == -2)][:, :-3], axis=0)\n",
    "    if errors.shape[0] == 0 or np.array_equal(errors, seq_errors):\n",
    "        print(f\"2. All tests terminated on sequential terminated on the given method\")\n",
    "    else:\n",
    "        print(f\"2. {errors.shape[0]} parallel tests did not terminate:\")\n",
    "        print(errors)\n",
    "        print(f\"2. While {seq_errors.shape[0]} sequential tests did not terminate:\")\n",
    "        print(seq_errors)\n",
    "\n",
    "    # Third check: non - run tests\n",
    "    non_run = dataset[np.where(dataset[:, -3] == -1)][:, :-3]\n",
    "    if non_run.shape[0] == 0:\n",
    "        print(f\"3. All tests where run\")\n",
    "    else:\n",
    "        print(f\"3. {non_run.shape[0]} tests have not been run:\")\n",
    "        print(non_run)\n",
    "\n",
    "    # Fourth check: correctness\n",
    "    dataset_runs = dataset[np.where(dataset[:, -3] >= 0)]\n",
    "    #dataset_runs = np.unique(dataset_runs[:, 1:], axis=0)\n",
    "    for i in range(dataset_runs.shape[0]):\n",
    "        flag = False\n",
    "        for j in range(sequential.shape[0]):\n",
    "            # The same setup has been found\n",
    "            if np.array_equal(dataset_runs[i, 1:-3], sequential[j, :-3]):\n",
    "                # The sequential run did not finish, thus it makes no sense to count it as an error\n",
    "                if np.array_equal(sequential[j, -3:], np.array([-2, -2, -2], dtype=np.int64)):\n",
    "                    flag = True\n",
    "\n",
    "                # The sequential did finish, so let's compare the actual values\n",
    "                if np.array_equal(dataset_runs[i, -3:], sequential[j, -3:]):\n",
    "                    flag = True\n",
    "        if not flag:\n",
    "            print(f\"4. Configuration {np.array2string(dataset_runs[i, :-3])} has wrong results\")\n",
    "    print(\"4. No other errors were found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. No errors\n",
      "2. 31 parallel tests did not terminate:\n",
      "[[20 10  4 10]\n",
      " [20 15  4  1]\n",
      " [20 15  4  2]\n",
      " [20 15  4  3]\n",
      " [20 15  4  4]\n",
      " [20 15  4  5]\n",
      " [20 15  4  6]\n",
      " [20 15  4  7]\n",
      " [20 15  4  8]\n",
      " [20 15  4  9]\n",
      " [20 15  4 10]\n",
      " [20 20  4  1]\n",
      " [20 20  4  2]\n",
      " [20 20  4  3]\n",
      " [20 20  4  4]\n",
      " [20 20  4  5]\n",
      " [20 20  4  6]\n",
      " [20 20  4  7]\n",
      " [20 20  4  8]\n",
      " [20 20  4  9]\n",
      " [20 20  4 10]\n",
      " [20 25  4  1]\n",
      " [20 25  4  2]\n",
      " [20 25  4  3]\n",
      " [20 25  4  4]\n",
      " [20 25  4  5]\n",
      " [20 25  4  6]\n",
      " [20 25  4  7]\n",
      " [20 25  4  8]\n",
      " [20 25  4  9]\n",
      " [20 25  4 10]]\n",
      "2. While 320 sequential tests did not terminate:\n",
      "[[10 25  4  1]\n",
      " [10 25  4  2]\n",
      " [10 25  4  3]\n",
      " ...\n",
      " [20 25 20  8]\n",
      " [20 25 20  9]\n",
      " [20 25 20 10]]\n",
      "3. 1680 tests have not been run:\n",
      "[[ 2 10 10  4  1]\n",
      " [ 2 10 10  4  2]\n",
      " [ 2 10 10  4  3]\n",
      " ...\n",
      " [ 8 20 25 20  8]\n",
      " [ 8 20 25 20  9]\n",
      " [ 8 20 25 20 10]]\n",
      "4. No other errors were found\n"
     ]
    }
   ],
   "source": [
    "correctness(\"results/logs/mpi_exp\", mpi_idx, retrieve_time_mpi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlcourse-BfLxQsIA-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
